{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d8e8529",
   "metadata": {},
   "source": [
    "# **ğŸ“˜ Module 8 â€“ Data Quality & Monitoring (Week 12\\)**\n",
    "\n",
    "This page is the handbook for Week 12 â€“ Data Quality & Monitoring in the Data Engineering & Analytics module.\n",
    "\n",
    "ğŸ¯ **Learning Objectives**  \n",
    " By the end of this week, you will be able to:\n",
    "\n",
    "* Explain the data quality lifecycle and where checks belong in a modern Medallion architecture.\n",
    "\n",
    "* Implement data validation with:\n",
    "\n",
    "  * Great Expectations (GX) on Spark data (Microsoft Fabric \\+ Amazon Sales dataset).\n",
    "\n",
    "  * Pydantic for config and row-level validation in Python.\n",
    "\n",
    "* Describe data observability and when to use tools like Monte Carlo and Datadog.\n",
    "\n",
    "* Add CI/CD around data pipelines using GitHub Actions or Jenkins, including automated GE checkpoints.\n",
    "\n",
    "  ---\n",
    "\n",
    "  # **1\\. Big Picture: Data Quality & Observability**\n",
    "\n",
    "  ## **1.1 Data Quality vs. Data Observability**\n",
    "\n",
    "**Data Quality (DQ):** Are the values correct, complete, consistent, and fit for purpose?  \n",
    " Examples: no null IDs, valid email format, totals match source system.\n",
    "\n",
    "ğŸ“º [Data Quality Explained](https://youtu.be/5HcDJ8e9NwY?si=BBlFx2cI8-yczVjb)\n",
    "\n",
    "**Data Observability:** Can we see when something breaks in the data or pipelines in real time?  \n",
    " Focus on freshness, volume, schema, distribution, lineage and alerts.\n",
    "\n",
    "A healthy platform needs both:\n",
    "\n",
    "* DQ rules (Great Expectations, Collibra DDQ, Pydantic models)\n",
    "\n",
    "* Observability & monitoring (Monte Carlo, Datadog, Slack alerts, dashboards)\n",
    "\n",
    "  ---\n",
    "\n",
    "  # **2\\. Data Validation**\n",
    "\n",
    "  # **2.1 Great Expectations (GX)**\n",
    "\n",
    "Great Expectations is an open-source framework for declarative data tests. You describe how the data should look, and GX validates your datasets against those expectations.\n",
    "\n",
    "## **2.1.1 Core Concepts**\n",
    "\n",
    "## **2.1.2 Typical GX Workflow**\n",
    "\n",
    "* Connect to data (Spark, SQL, pandas, etc.).\n",
    "\n",
    "* Create an Expectation Suite:\n",
    "\n",
    "  * Start with profiling (auto-suggested expectations).\n",
    "\n",
    "  * Then refine manually.\n",
    "\n",
    "* Define a Checkpoint â€“ which suite(s) \\+ what batch.\n",
    "\n",
    "* Run validations:\n",
    "\n",
    "  * Locally, in a notebook.\n",
    "\n",
    "  * Inside pipeline steps (Fabric, ADF, Airflow, etc.).\n",
    "\n",
    "* Publish Data Docs and send alerts if validation fails.\n",
    "\n",
    "  ## **2.1.3 Great Expectations â€“ Watchlist & Readlist**\n",
    "\n",
    "  ğŸ“º[Great Expectations (GX) for DATA Testing \\- Introduction](https://www.youtube.com/playlist?list=PLYDwWPRvXB8_XOcrGlYLtmFEZywOMnGSS)  \n",
    "  ğŸ“º[Implementing Data Quality in Python w/ Great Expectations](https://www.youtube.com/playlist?list=PLYDwWPRvXB8_XOcrGlYLtmFEZywOMnGSS)\n",
    "\n",
    "  ğŸ“šGE Official docs â€“ [https://docs.greatexpectations.io/](https://docs.greatexpectations.io/)  \n",
    "  ğŸ“šDatacamp tutorial â€“ [https://www.datacamp.com/tutorial/great-expectations-tutorial](https://www.datacamp.com/tutorial/great-expectations-tutorial)  \n",
    "  ğŸ“šMicrosoft Fabric example â€“ [https://devblogs.microsoft.com/ise/data-validations-with-great-expectations-in-ms-fabric](https://devblogs.microsoft.com/ise/data-validations-with-great-expectations-in-ms-fabric)\n",
    "\n",
    "  ---\n",
    "\n",
    "  # **â­ HOMEWORK 1 â€” Great Expectations with Pandas (Local Project)**\n",
    "\n",
    "  ### **ğŸ¯ Goal**\n",
    "\n",
    "Understand the fundamentals of Great Expectations by validating a CSV file locally using Pandas.\n",
    "\n",
    "### **âœ” Tasks**\n",
    "\n",
    "1. Load your CSV (Amazon subset or any small dataset) using Pandas.\n",
    "\n",
    "2. Initialize a Great Expectations project.\n",
    "\n",
    "3. Create an expectation suite.\n",
    "\n",
    "4. Add at least **5 rules**, such as:\n",
    "\n",
    "   * `order_id` cannot be null\n",
    "\n",
    "   * `quantity > 0`\n",
    "\n",
    "   * `price >= 0`\n",
    "\n",
    "   * `ship_date >= order_date`\n",
    "\n",
    "   * `country` in the allowed set\n",
    "\n",
    "5. Run validation.\n",
    "\n",
    "6. Export results to:\n",
    "\n",
    "   * `expectations.json`\n",
    "\n",
    "   * `gx_report.json`\n",
    "\n",
    "   ### **âœ” Output**\n",
    "\n",
    "1. `/homework1/`  \n",
    "2.   `expectations.json`  \n",
    "3.   `gx_report.json`  \n",
    "4.   `script.py or notebook`  \n",
    "     \n",
    "   ---\n",
    "\n",
    "   # **2.2 Pydantic for Schema & Config Validation**\n",
    "\n",
    "Pydantic is a Python library that uses type hints to validate data. It is ideal for:\n",
    "\n",
    "* Validating pipeline configuration (paths, thresholds, email lists, etc.).\n",
    "\n",
    "* Enforcing schemas for JSON payloads, API responses, or intermediate objects.\n",
    "\n",
    "* Building reliable internal DTOs (Data Transfer Objects) for your data apps.\n",
    "\n",
    "We focus on **Pydantic v2**.\n",
    "\n",
    "## **2.2.1 Pydantic â€“ Watchlist & Readlist**\n",
    "\n",
    "ğŸ“º[Pydantic V2 - Full Course - Learn the BEST Library for Data Validation and Parsing](https://youtu.be/7aBRk_JP-qY)  \n",
    "ğŸ“º[Pydantic Tutorial â€¢ Solving Python's Biggest Problem](https://youtu.be/XIdQ6gO3Anc)\n",
    "\n",
    "ğŸ“šPydantic Models â€“ [https://docs.pydantic.dev/latest/concepts/models/](https://docs.pydantic.dev/latest/concepts/models/)  \n",
    "ğŸ“šValidators â€“ [https://docs.pydantic.dev/latest/concepts/validators/](https://docs.pydantic.dev/latest/concepts/validators/)\n",
    "\n",
    "ğŸ“šReal Python intro â€“ [https://realpython.com/python-pydantic/](https://realpython.com/python-pydantic/)\n",
    "\n",
    "---\n",
    "\n",
    "# **â­ HOMEWORK 2 â€” Pydantic (Row-Level \\+ Config Validation)**\n",
    "\n",
    "### **ğŸ¯ Goal**\n",
    "\n",
    "Use Pydantic models to validate rows and pipeline configuration.\n",
    "\n",
    "### **âœ” Tasks**\n",
    "\n",
    "1. Define an `Order` model with constraints:\n",
    "\n",
    "   * `quantity > 0`\n",
    "\n",
    "   * `price >= 0`  \n",
    "       \n",
    "   * etc.\n",
    "\n",
    "2. Load CSV and validate each row.\n",
    "\n",
    "3. Write valid and invalid rows to:\n",
    "\n",
    "   * `valid_rows.csv`\n",
    "\n",
    "   * `invalid_rows.csv`\n",
    "\n",
    "4. Create a `config.yaml` with thresholds & allowed values.\n",
    "\n",
    "5. Validate config using Pydantic.\n",
    "\n",
    "   ### **âœ” Output**\n",
    "\n",
    "5. `/homework2/`  \n",
    "6.   `valid_rows.csv`  \n",
    "7.   `invalid_rows.csv`  \n",
    "8.   `config.yaml`  \n",
    "9.   `validation.py`  \n",
    "     \n",
    "   ---\n",
    "\n",
    "   # **3\\. Data Observability**\n",
    "\n",
    "Data observability tools like Monte Carlo and Datadog help answer:\n",
    "\n",
    "â€œIs my data pipeline healthy right now and who is impacted if something goes wrong?â€\n",
    "\n",
    "Key monitored pillars:\n",
    "\n",
    "* Freshness\n",
    "\n",
    "* Volume\n",
    "\n",
    "* Schema\n",
    "\n",
    "* Distribution\n",
    "\n",
    "* Lineage\n",
    "\n",
    "ğŸ“º [What is Data Observability?](https://youtu.be/jfg9wBJBtKk?si=ezqKJYbpo7my2_rk)\n",
    "\n",
    "---\n",
    "\n",
    "# **3.1 Monte Carlo**\n",
    "\n",
    "Monte Carlo is a Data \\+ AI Observability platform that connects to your data warehouses, lakes, ETL tools, and BI dashboards.\n",
    "\n",
    "## **3.1.1 What Monte Carlo Monitors**\n",
    "\n",
    "* Freshness, volume, nulls, uniqueness\n",
    "\n",
    "* Incidents\n",
    "\n",
    "* Lineage\n",
    "\n",
    "* SLAs/SLOs\n",
    "\n",
    "  ## **3.1.2 Monte Carlo â€“ Watchlist & Readlist**\n",
    "\n",
    "ğŸ“º [2025: Monte Carlo Data \\+ AI Observability Platform Demo](https://www.youtube.com/watch?v=MmvZY1gTAy4)\n",
    "\n",
    "ğŸ“š [https://www.montecarlodata.com/data-observability-overview/](https://www.montecarlodata.com/data-observability-overview/)  \n",
    " ğŸ“š [https://docs.getmontecarlo.com/docs/architecture](https://docs.getmontecarlo.com/docs/architecture)  \n",
    " ğŸ“š [https://www.montecarlodata.com/blog-what-is-data-observability/](https://www.montecarlodata.com/blog-what-is-data-observability/)\n",
    "\n",
    "# **â­ Exercise â€” End-to-end observability-Demo**\n",
    "\n",
    "âš’ï¸ https://www.montecarlodata.com/platform/data-quality/\n",
    "\n",
    "---\n",
    "\n",
    "# **3.2 Datadog for Data Stack Monitoring**\n",
    "\n",
    "Use Datadog to:\n",
    "\n",
    "* Collect logs\n",
    "\n",
    "* Monitor pipeline metrics\n",
    "\n",
    "* Create alerts\n",
    "\n",
    "* Track Spark jobs\n",
    "\n",
    "* Build dashboards\n",
    "\n",
    "  ## **3.2.1 Datadog â€” Watchlist & Readlist**\n",
    "\n",
    "ğŸ“º [Datadog 101 Course | Datadog Tutorial for Beginners | SRE | DevOps](https://www.youtube.com/watch?v=Js06FTU3nXo)  \n",
    " ğŸ“º [L01 - Datadog Log Intro: Logging Philosophy](https://youtu.be/-64x697bELI?si=2HI2oR4sZ7a_bFDi)\n",
    "\n",
    "ğŸ“˜ Courses:\n",
    "\n",
    "* ğŸ“’ [https://learn.datadoghq.com/courses/log-explorer](https://learn.datadoghq.com/courses/log-explorer)\n",
    "\n",
    "* ğŸ“’ [https://learn.datadoghq.com/courses/getting-started-metrics](https://learn.datadoghq.com/courses/getting-started-metrics)\n",
    "\n",
    "* ğŸ“’ [https://learn.datadoghq.com/courses/getting-started-monitors](https://learn.datadoghq.com/courses/getting-started-monitors)\n",
    "\n",
    "ğŸ“š [https://docs.datadoghq.com/logs/log\\_configuration/pipelines/](https://docs.datadoghq.com/logs/log_configuration/pipelines/)  \n",
    " ğŸ“š [https://docs.datadoghq.com/logs/log\\_configuration/logs\\_to\\_metrics/](https://docs.datadoghq.com/logs/log_configuration/logs_to_metrics/)  \n",
    " ğŸ“š [https://www.datadoghq.com/architecture/a-guide-to-log-management-indexing-strategies-with-datadog/](https://www.datadoghq.com/architecture/a-guide-to-log-management-indexing-strategies-with-datadog/)\n",
    "\n",
    "---\n",
    "\n",
    "# **4\\. CI/CD for Data Pipelines**\n",
    "\n",
    "CI/CD for data teams means:\n",
    "\n",
    "* Automatically testing pipeline code\n",
    "\n",
    "* Running GE checks\n",
    "\n",
    "* Deploying notebooks, SQL objects, dbt models\n",
    "\n",
    "We focus on **GitHub Actions** and **Jenkins**.\n",
    "\n",
    "---\n",
    "\n",
    "# **4.1 GitHub Actions**\n",
    "\n",
    "GitHub Actions uses YAML workflows stored in `.github/workflows/`.\n",
    "\n",
    "## **4.1.1 Watchlist & Readlist**\n",
    "\n",
    "ğŸ“º [GitHub Actions Tutorial - Basic Concepts and CI/CD Pipeline with Docker](https://youtu.be/R8_veQiYBjI?si=CDcxTTH4CM1qloK3)  \n",
    "ğŸ“º [GitHub Actions CI/CD pipeline | Step by Step guide](https://youtu.be/a5qkPEod9ng?si=t3s5FpLeiLqRLiOF)\n",
    "\n",
    "ğŸ“š GitHub blog:  \n",
    " [https://github.blog/enterprise-software/ci-cd/keeping-your-data-pipelines-healthy-with-the-great-expectations-github-action/](https://github.blog/enterprise-software/ci-cd/keeping-your-data-pipelines-healthy-with-the-great-expectations-github-action/)\n",
    "\n",
    "ğŸ“š GE Blog:  \n",
    " [https://greatexpectations.io/blog/github-actions/](https://greatexpectations.io/blog/github-actions/)\n",
    "\n",
    "ğŸ“š Datacamp:  \n",
    " [https://www.datacamp.com/blog/ci-cd-in-data-engineering](https://www.datacamp.com/blog/ci-cd-in-data-engineering)\n",
    "\n",
    "---\n",
    "\n",
    "# **â­ HOMEWORK 3 â€” GitHub Actions CI Pipeline for Data Quality**\n",
    "\n",
    "### **ğŸ¯ Goal**\n",
    "\n",
    "Run Great Expectations automatically on every GitHub push.\n",
    "\n",
    "### **âœ” Tasks**\n",
    "\n",
    "1. Create a GitHub repo.\n",
    "\n",
    "2. Add your validation script under `/src/`.\n",
    "\n",
    "3. Create `.github/workflows/dq-check.yml` that:\n",
    "\n",
    "   * installs Python\n",
    "\n",
    "   * installs dependencies\n",
    "\n",
    "   * runs your validation\n",
    "\n",
    "   * fails pipeline if DQ fails\n",
    "\n",
    "4. Confirm: pipeline turns **red** on failure.\n",
    "\n",
    "   ### **âœ” Output**\n",
    "\n",
    "* Repo link\n",
    "\n",
    "* Screenshot of failed/passed workflow\n",
    "\n",
    "  ---\n",
    "\n",
    "  # **â­ HOMEWORK 4 â€” Slack Notification for Data Quality Failures**\n",
    "\n",
    "  ### **ğŸ¯ Goal**\n",
    "\n",
    "Send Slack alerts when DQ validation fails.\n",
    "\n",
    "### **âœ” Tasks**\n",
    "\n",
    "1. Create an **Incoming Webhook** in Slack.\n",
    "\n",
    "2. Write a Python function that sends a message to Slack on failure.\n",
    "\n",
    "3. Integrate this function into your validation script.\n",
    "\n",
    "4. Add a Slack notification step to GitHub Actions.\n",
    "\n",
    "   ### **âœ” Output**\n",
    "\n",
    "* Slack message screenshot\n",
    "\n",
    "* Updated workflow file\n",
    "\n",
    "  ---\n",
    "\n",
    "  # **4.2 Jenkins**\n",
    "\n",
    "ğŸ“º [Master Jenkins Pipelines | Step by Step Tutorial for Beginners | KodeKloud](https://youtu.be/hgUGblYj-JQ?si=48l6S-xuwNtUZQ8X)  \n",
    " ğŸ“º [Complete Jenkins Pipeline Tutorial | Jenkinsfile explained | KodeKloud](https://youtu.be/EzgCoOQvOf0?si=KTuPIWKuiF6AHNWU)\n",
    "\n",
    "ğŸ“š [https://www.jenkins.io/doc/book/pipeline/](https://www.jenkins.io/doc/book/pipeline/)  \n",
    " ğŸ“š [https://www.jenkins.io/doc/pipeline/examples/](https://www.jenkins.io/doc/pipeline/examples/)\n",
    "\n",
    "---\n",
    "\n",
    "# **5\\. Collibra DDQ â€“ Profiling & Quality Controls** \n",
    "\n",
    "**ğŸ“º**[Collibra | Streamline Your Customer Product Sales Data with Collibra | Part - 1](https://www.youtube.com/watch?v=BtKb1uKLH18&list=PLfMV70VIUv4smY3BlLlUs98_PUnxYYD_x)\n",
    "\n",
    "**ğŸ“º**[Collibra Data Quality & Observability: Out-of-the-box Features](https://youtu.be/T-MBwqokhkQ?si=KVPRrpKhTp1pvH7q)\n",
    "\n",
    "**ğŸ“š**https://www.collibra.com/blog/what-is-data-quality\n",
    "\n",
    "---\n",
    "\n",
    "# **ğŸš€ Final Project (In-Class)**\n",
    "\n",
    "A short end-to-end Microsoft Fabric project where you will apply Week 12 concepts by validating the **Amazon Sales** dataset using **Great Expectations on Spark** and sending **Slack alerts** when validation fails.\n",
    "\n",
    "**Good Luck\\!**\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
