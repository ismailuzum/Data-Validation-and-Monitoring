# Data-Validation-and-Monitoring
Data Quality &amp; Monitoring in the Data Engineering &amp; Analytics module

ðŸŽ¯ Learning Objectives

By the end of this week you will be able to:

Explain the data quality lifecycle and where checks belong in a modern Medallion architecture.

Implement data validation with:

Great Expectations (GX) on Spark data (Microsoft Fabric + Amazon Sales dataset).

Pydantic for config and rowâ€‘level validation in Python.

Describe data observability and when to use tools like Monte Carlo and Datadog.

Apply logging & error handling patterns in data pipelines.

Add CI/CD around data pipelines using GitHub Actions or Jenkins, including automated GE checkpoints.

Use Collibra DDQ for profiling and businessâ€‘level data quality and send results to Slack.
